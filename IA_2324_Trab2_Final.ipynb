{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ada5080",
   "metadata": {},
   "source": [
    "# 2º Trabalho de Inteligência Artificial\n",
    "##### Trabalho Realizado por Francisco Tavares, Rodrigo Batista e Rodrigo Taveira"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6178dd",
   "metadata": {},
   "source": [
    "## Índice\n",
    "\n",
    "1. [Introdução](#Introdução)\n",
    "\n",
    "2. [Objetivo](#Objetivo)\n",
    "\n",
    "3. [Funções auxiliares](#Funções-auxiliares)\n",
    "\n",
    "4. [Construção da árvore](#Construção-da-árvore)\n",
    "\n",
    "5. [Menus](#Menus)\n",
    "\n",
    "6. [Divisão dos dados](#Divisão-dos-dados)\n",
    "\n",
    "7. [Previsão de dados](#Previsão-de-dados)\n",
    "\n",
    "8. [Datasets](#Datasets)\n",
    "\n",
    "9. [Testes e resultados](#Testes-e-resultados)\n",
    "\n",
    "10. [Datasets](#Datasets)\n",
    "\n",
    "11. [Conclusão](#Conclusão)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a78fdc9",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9511db8d",
   "metadata": {},
   "source": [
    "Este trabalho tem como objetivo explorar e implementar um algoritmo de árvores de decisão, baseado no conceito apresentado no livro \"Artificial Intelligence: a Modern Approach\" de Stuart Russell e Peter Norvig.\n",
    "Será adoptado um algoritmo semelhante ao ID3, que utiliza a entropia como medida de seleção de atributos para construir a árvore de decisao.\n",
    "\n",
    "Além disso, este trabalho abrange a implementação do algoritmo em diferentes conjuntos de dados. Esta abordagem permite explorar a eficácia e versatilidade da árvore de decisão em diferentes contextos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71db9533",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "O objetivo deste trabalho é estudar e compreender a implementação de uma decision tree. Também iremos estudar a influência de determinados parâmetros na construção das mesmas bem como a importância de resolver problemas tal como o class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcf1ccf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T11:44:17.722380Z",
     "start_time": "2024-05-20T11:44:15.902619Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from scrapy.spidermiddlewares import depth\n",
    "import random \n",
    "import copy\n",
    "import math\n",
    "\n",
    "from Trabalho_IA_versao_DECISION_TREE import ConnectFour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6446eeb6",
   "metadata": {},
   "source": [
    "## Funções auxiliares\n",
    "\n",
    "[Go back to the top](#Índice)\n",
    "\n",
    "-Função __choose_best_attribute__(attributes, examples): Esta função com base na entropia e na informação ganha calcula o melhor atributo.\n",
    "\n",
    "-Função __plurality_value__(examples): Esta função em termos de implementação, começa por fazer uma contagem das ocorrências das classes, onde depois o máximo desta contagem é determinado usando a função 'max()'. Se houver mais do que uma classe com a mesma contagem máxima, a função escolhe aleatoriamente uma das classes.\n",
    "\n",
    "-Função __calculate_attribute_entropy__(examples, attribute): Esta função calcula a entropia de um atributo\n",
    "\n",
    "-Função __entropy__(class1): Esta função é responsável por calcular a entropia.\n",
    "\n",
    "-Função __calculate_numeric_splits__(examples,attribute): Esta função está responsável por calcular o valor que melhor separa o dataset para os atributos númericos. Faz isso através do cálculo da informação ganha.\n",
    "\n",
    "-Função __information_gain__(parent_class,class1,class2): Esta função calcula o ganho de informação. Usa a função __calculate_entropy__.\n",
    "\n",
    "-Função __attribute_values__(attribute, dataframe): Nesta função são retornados todos os valores únicos de um atributo\n",
    "\n",
    "-Função __transform_boolean__(examples): Transforma todos os valores booleanos 'True' e 'False' em 'Yes' e 'No'.\n",
    "\n",
    "-Função __subset_with_attribute_value__(attribute, value, dataframe): Cria um dataset com os dados com valor igual ao value inserido.\n",
    "\n",
    "-Função __subset_with_attribute_value_numeric__(attribute, value, operator, examples): Cria um dataset com dados \"<=\" ou \">\" que o valor dado, dependendo do operator inserido.\n",
    "\n",
    "-Função __all_same_class__(examples): Esta função retorna True se todas as entradas forem da mesma classe. Retorna False caso haja, pelo menos, um diferente.\n",
    "\n",
    "-Função __print_decision_tree__(tree, depth=0): Esta função é responsável por imprimir a árvore no formato pedido pelo professor.\n",
    "\n",
    "-Função __prever_classe__(arvore, caminho): Nesta função é usado a árvore e o caminho gerado pela função __caminho_dados__ para prever a classe de um determinado dado.\n",
    "\n",
    "-Função __caminho_dados__(instancia, arvore): Esta função percorre a árvore (dicionário) e retorna o caminho de uma determinada entrada do dataset. Esta função consegue lidar com dados numéricos e strings.\n",
    "\n",
    "-Função __prever_dataset__(df, arvore): Esta função prevê a classe de todas as entradas de um dataset. Para isso percorre todas as linhas e usa as funções __caminho_dados__ e __prever_classe__.\n",
    "\n",
    "-Função __accuracy__(dataset,previsoes): Esta função retorna-nos a accuracy. Se a classe prevista for igual à classe \"real\" adiciona mais um ao contador e ao total, caso não seja soma apenas ao total. \n",
    "\n",
    "-Função __predict_new_example__(dt,new_example): Esta função está responsável por adicionar um novo exemplo ao dataset para poder ser avaliado. Começa por separar todos os valores pelas vírgulas e por anotar os tipos do dataset num vetor. De seguida percorre todos os tipos e caso seja um inteiro ou um float transforma os dados lidos no respetivo tipo. Por fim acrescenta a nova linha ao dataset e retorna o dataset. \n",
    "\n",
    "-Função __over_sample__(df): Esta é uma função de pré processamento responsável por aumentar a classe em menor número em datasets com classes desbalanceadas (neste caso o dataset 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d608974ae8071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T11:44:17.800332Z",
     "start_time": "2024-05-20T11:44:17.757276Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def choose_best_attribute(attributes, examples):\n",
    "\n",
    "    entropy = calculate_entropy(examples[examples.columns[-1]].tolist())\n",
    "    infos_gain = []\n",
    "      \n",
    "    for attribute in attributes:\n",
    "        entropy_attribute=calculate_attribute_entropy(examples, attribute)\n",
    "        info_gain=entropy - entropy_attribute\n",
    "        infos_gain.append(info_gain)\n",
    "    \n",
    "    maximo=float('-inf')\n",
    "    indice=0\n",
    "    for i in range (len(infos_gain)):\n",
    "        if infos_gain[i]>maximo:\n",
    "            maximo=infos_gain[i]\n",
    "            indice=i\n",
    "    \n",
    "    best_attribute=attributes[indice]\n",
    "    \n",
    "    return best_attribute\n",
    "    \n",
    "\n",
    "def plurality_value(examples):\n",
    "    counts = {}\n",
    "    for i in range(examples.shape[0]):\n",
    "        classification = examples.iloc[i, -1] \n",
    "        counts[classification] = counts.get(classification, 0) + 1\n",
    "\n",
    "    max_count = max(counts.values())\n",
    "    common_values = [value for value, count in counts.items() if count == max_count]\n",
    "\n",
    "    return random.choice(common_values)\n",
    "    \n",
    "def calculate_attribute_entropy(examples,attribute):\n",
    "    \n",
    "    values=attribute_values(attribute,examples)\n",
    "    entropy_attribute=0\n",
    "    \n",
    "    for value in values:\n",
    "        subset = subset_with_attribute_value(attribute, value, examples)\n",
    "        subset_labels = subset[examples.columns[-1]]\n",
    "        subset_entropy = calculate_entropy(subset_labels)\n",
    "        subset_probability = subset.shape[0]/examples.shape[0]\n",
    "        entropy_attribute +=subset_probability * subset_entropy\n",
    "        \n",
    "    return entropy_attribute\n",
    "\n",
    "def calculate_entropy(class1):\n",
    "    \n",
    "    label_counts = Counter(class1)\n",
    "    total_samples = len(class1)\n",
    "    entropy = 0\n",
    "    \n",
    "    for count in label_counts.values():\n",
    "        probability = count / total_samples\n",
    "        entropy -= probability * math.log2(probability)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def calculate_numeric_splits(examples,attribute):\n",
    "    \n",
    "    values=attribute_values(attribute,examples)\n",
    "    best_split= None\n",
    "    best_info_gain= float('-inf')\n",
    "    \n",
    "    if len(values) == 1:\n",
    "        return values[0]\n",
    "    \n",
    "    for value in values:\n",
    "        subset1 = subset_with_attribute_value_numeric(attribute, value, \"<= \", examples)\n",
    "        subset2 = subset_with_attribute_value_numeric(attribute, value, \"> \", examples)\n",
    "        \n",
    "        labels1 = subset1[examples.columns[-1]]\n",
    "        labels2 = subset2[examples.columns[-1]]\n",
    "\n",
    "        info_gain = information_gain(examples[examples.columns[-1]], labels1, labels2)\n",
    "\n",
    "        if info_gain > best_info_gain:\n",
    "            best_info_gain = info_gain\n",
    "            best_split = value\n",
    "\n",
    "    return best_split\n",
    "\n",
    "def information_gain(parent_class,class1,class2):\n",
    "    parent_entropy = calculate_entropy(parent_class)\n",
    "    weight1 = len(class1) / len(parent_class)\n",
    "    weight2 = len(class2) / len(parent_class)\n",
    "    entropy1 = calculate_entropy(class1)\n",
    "    entropy2 = calculate_entropy(class2)\n",
    "    info_gain = parent_entropy - (weight1 * entropy1) - (weight2 * entropy2)\n",
    "    return info_gain\n",
    "\n",
    "def attribute_values(attribute, dataframe):\n",
    "    return dataframe[attribute].unique()\n",
    "\n",
    "def transform_boolean(examples):\n",
    "    examples.replace({True: \"Yes\", False: \"No\"}, inplace=True)\n",
    "\n",
    "def subset_with_attribute_value(attribute, value, dataframe):\n",
    "    subset = dataframe[dataframe[attribute] == value]\n",
    "    #print(subset)\n",
    "    return subset\n",
    "\n",
    "def subset_with_attribute_value_numeric(attribute, value, operator, examples):\n",
    "    if operator == \"<= \":\n",
    "        subset = examples[examples[attribute] <= value]\n",
    "    elif operator == \"> \":\n",
    "        subset = examples[examples[attribute] > value]    \n",
    "    return subset\n",
    "\n",
    "def all_same_class(examples):\n",
    "    for i in range (examples.shape[0]):\n",
    "        example= examples.iloc[i,-1]\n",
    "        if example != examples.iloc[0,-1]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def print_decision_tree(tree, depth=0):\n",
    "    if isinstance(tree, dict):\n",
    "        for attribute, subtree in tree.items():\n",
    "            print(\"  \" * depth + \"<\" + attribute + \">\")\n",
    "            for value, subtree_or_class in subtree.items():\n",
    "                if isinstance(subtree_or_class, dict):\n",
    "                    print(\"  \" * (depth + 1) + value + \":\")\n",
    "                    print_decision_tree(subtree_or_class, depth + 2)\n",
    "                else:\n",
    "                    if \"(\" in subtree_or_class:\n",
    "                        counter=0\n",
    "                        class_, counter = subtree_or_class.split(\" (\")\n",
    "                        class_ = class_.strip()\n",
    "                        counter = counter.replace(\")\", \"\").strip()\n",
    "                        print(\"  \" * (depth + 1) + value + \": \" + class_ + \" (\" + counter + \")\")\n",
    "                    else:\n",
    "                        print(\"  \" * (depth + 1) + value + \": \" + subtree_or_class)\n",
    "    else:\n",
    "        print(\"  \" * depth + tree)\n",
    "\n",
    "def prever_classe(arvore, caminho):\n",
    "    no_atual = arvore\n",
    "    \n",
    "    for passo in caminho:\n",
    "        if isinstance(no_atual, dict) and passo in no_atual:\n",
    "            no_atual = no_atual[passo]\n",
    "        else:\n",
    "            return \"Caminho não encontrado na árvore\"\n",
    "    \n",
    "    if isinstance(no_atual, str):\n",
    "        classe = no_atual.split(' ')[0]\n",
    "        return classe\n",
    "    else:\n",
    "        return \"Caminho não leva a uma classe final\"\n",
    "\n",
    "def caminho_dados(instancia, arvore):\n",
    "    caminho = []\n",
    "    no_atual = arvore\n",
    "    while isinstance(no_atual, dict):\n",
    "        atributo = next(iter(no_atual))\n",
    "        if atributo not in instancia:\n",
    "            print(\"Atributo:\", atributo)\n",
    "            return None  # Atributo não encontrado na instância\n",
    "        valor = instancia[atributo]\n",
    "        \n",
    "        for chave in no_atual[atributo]:\n",
    "            if chave.startswith('<= ') or chave.startswith('> '):\n",
    "                comparacao, limite = chave.split(' ')\n",
    "                limite = float(limite)\n",
    "                if (comparacao == '<=' and valor <= limite) or (comparacao == '>' and valor > limite):\n",
    "                    caminho.append(atributo)\n",
    "                    caminho.append(chave)\n",
    "                    no_atual = no_atual[atributo][chave]\n",
    "                    break\n",
    "            elif valor == chave:\n",
    "                caminho.append(atributo)\n",
    "                caminho.append(chave)\n",
    "                no_atual = no_atual[atributo][chave]\n",
    "                break\n",
    "        else:\n",
    "            return None  # Caminho não encontrado para o valor do atributo\n",
    "    return caminho\n",
    "\n",
    "def prever_dataset(df, arvore):\n",
    "    previsoes = []\n",
    "    for _, instancia in df.iterrows():\n",
    "        caminho = caminho_dados(instancia, arvore)\n",
    "        if caminho is None:\n",
    "            previsoes.append(\"Caminho não encontrado na árvore\")\n",
    "        else:\n",
    "            classe = prever_classe(arvore, caminho)\n",
    "            previsoes.append(classe)\n",
    "    return previsoes\n",
    "    \n",
    "\n",
    "def accuracy(dataset,previsoes):\n",
    "    cont=0\n",
    "    total=0\n",
    "    for i in range (len(previsoes)):\n",
    "        if (previsoes[i] == dataset.iloc[i,-1]):\n",
    "            cont+=1\n",
    "            total+=1\n",
    "        else:\n",
    "            total+=1\n",
    "    return cont/total\n",
    "\n",
    "def predict_new_example(dt,new_example):\n",
    "\n",
    "    values = [valor.strip() for valor in new_example.split(',')]\n",
    "\n",
    "    tipos=dt.dtypes\n",
    "\n",
    "    for i in range (len(values)):\n",
    "        if tipos[i]=='int64':\n",
    "            values[i]=int(values[i])\n",
    "        if tipos[i]=='float64':\n",
    "            values[i]=float(values[i])\n",
    "\n",
    "\n",
    "    dt1 = pd.DataFrame(values)\n",
    "    dados_nova_linha = {nome_coluna: [valor] for nome_coluna, valor in zip(dt.columns, values)}\n",
    "    dt= pd.concat([dt, pd.DataFrame(dados_nova_linha)], ignore_index=True)\n",
    "    return dt\n",
    "\n",
    "def over_sample(df):\n",
    "    last_column=df.columns[-1]\n",
    "    valor = df[last_column].mode()[0]\n",
    "    df_majority = df[df[last_column] == valor]\n",
    "    df_minority = df[df[last_column] != valor]\n",
    "    \n",
    "    df_minority_upsampled = resample(df_minority, \n",
    "                                     replace=True,     \n",
    "                                     n_samples=len(df_majority),    \n",
    "                                     random_state=123) \n",
    "\n",
    "    df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "    \n",
    "    return df_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef40de",
   "metadata": {},
   "source": [
    "## Construção da árvore\n",
    "\n",
    "[Go back to the top](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e1ebee",
   "metadata": {},
   "source": [
    "Esta é a função responsável por gerar a árvore. Seguindo o manual da disciplina, esta função recursiva escolhe o melhor atributo através da função __choose_best_attribute__. De seguida é criado um nó com esse atributo e guardado em duas variáveis os valores únicos restantes desse atributo e todos os valores únicos desse atributo no ínicio do dataset.\n",
    "De seguida é verificado se os valores são inteiros/floats. Caso sejam, estes dados são lidados de maneira diferente, através da definição de intervalos. É calculado o melhor valor para dividir os dados e depois são divididos em <= e > que esse valor. Após isso é chamada novamente a função onde são passados todos os atributos menos aquele já usado.\n",
    "Caso não sejam inteiros/float, são percorridos todos os valores e os dados divididos baseando-se nesse valor. Caso não haja mais exemplos retorna a classe mais comum. De realçar também o caso onde são \"perdidos\" valores e por isso tivemos de fazer uma condição para adicionar esse valor à árvore com contador igual a 0.\n",
    "\n",
    "Falando brevemente dos caso base, o primeiro caso refere-se a não haver mais dados, então é retornada a classe com maior número. O segundo refere-se a todos os dados serem da mesma classe e o terceiro a não haver mais atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4678796901fa2cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T11:44:17.816275Z",
     "start_time": "2024-05-20T11:44:17.802276Z"
    }
   },
   "outputs": [],
   "source": [
    "def learn_decision_tree(examples, attributes, parent_examples):\n",
    "    if len(examples) == 0:\n",
    "        class_ = plurality_value(parent_examples)\n",
    "        counter = len(examples)\n",
    "        return f\"{class_} ({counter})\"\n",
    "    \n",
    "    if all_same_class(examples):\n",
    "        class_ = examples.iloc[0,-1]\n",
    "        counter = len(examples)\n",
    "        return f\"{class_} ({counter})\"\n",
    "    \n",
    "    if len(attributes) == 0:\n",
    "        class_ = plurality_value(examples)\n",
    "        counter = len(examples)\n",
    "        return f\"{class_} ({counter})\"\n",
    "    \n",
    "    best_attribute = choose_best_attribute(attributes, examples)\n",
    "    tree = {best_attribute: {}}\n",
    "    \n",
    "    values = attribute_values(best_attribute, examples)\n",
    "    all_attribute_values = set(attribute_values(best_attribute, dt))\n",
    "    set_values=set(values)\n",
    "    \n",
    "    if isinstance(values[0], (int, float, np.int64)):\n",
    "        best_split = calculate_numeric_splits(examples, best_attribute)\n",
    "        \n",
    "        subset1 = subset_with_attribute_value_numeric(best_attribute, best_split, \"<= \", examples)\n",
    "        subset2 = subset_with_attribute_value_numeric(best_attribute, best_split, \"> \", examples)\n",
    "        \n",
    "        subtree1 = learn_decision_tree(subset1, [attr for attr in attributes if attr != best_attribute], examples)\n",
    "        subtree2 = learn_decision_tree(subset2, [attr for attr in attributes if attr != best_attribute], examples)\n",
    "        \n",
    "        tree[best_attribute][\"<= \" + str(best_split)] = subtree1\n",
    "        tree[best_attribute][\"> \" + str(best_split)] = subtree2\n",
    "    else:\n",
    "        for class_value in all_attribute_values - set_values:\n",
    "            class_=examples.iloc[0,-1]\n",
    "            tree[best_attribute][class_value] = f\"{class_} (0)\"\n",
    "        for value in values:\n",
    "            subset = subset_with_attribute_value(best_attribute, value, examples)\n",
    "            if len(subset) == 0:\n",
    "                subtree = plurality_value(examples)\n",
    "            else:\n",
    "                subtree = learn_decision_tree(subset, [attr for attr in attributes if attr != best_attribute], examples)\n",
    "            tree[best_attribute][value] = subtree\n",
    "    \n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7d12fb",
   "metadata": {},
   "source": [
    "## Menus\n",
    "\n",
    "[Go back to the top](#Índice)\n",
    "\n",
    "Neste pedaço de código estão presentes as funções correspondentes aos menus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8fabc03021b5a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T11:44:17.832351Z",
     "start_time": "2024-05-20T11:44:17.819275Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def menu_1():\n",
    "    print(\"Welcome to Decision Tree Classifier!\")\n",
    "    print(\"Choose between each type of data\")\n",
    "    print(\"1. Full set\")\n",
    "    print(\"2. Train/test set\")\n",
    "\n",
    "    choice = input(\"Enter your choice: \")\n",
    "    tamanho=0.0\n",
    "    div=False\n",
    "    \n",
    "    if choice == '2':\n",
    "        \n",
    "        tamanho=float(input(\"Enter the test data size (0.0 to 0.9): \"))\n",
    "        \n",
    "        div=True\n",
    "        \n",
    "    dt,ID_dataset=menu_2()\n",
    "    \n",
    "    return dt,div,tamanho,ID_dataset\n",
    "\n",
    "def menu_2():\n",
    "    print(\"Choose your dataset\")\n",
    "    print(\"1. Restaurant\")\n",
    "    print(\"2. Weather\")\n",
    "    print(\"3. Iris\")\n",
    "    print(\"4. ConnectFour\")\n",
    "    \n",
    "    choice = input(\"Enter the dataset number: \")\n",
    "    \n",
    "    ID_dataset=0\n",
    "    \n",
    "    if choice == '1':\n",
    "        dt=pd.read_csv('restaurant.csv')\n",
    "        dt.drop(dt.columns[0], axis=1, inplace=True)\n",
    "        ID_dataset=1\n",
    "        \n",
    "    elif choice == '2':\n",
    "        dt=pd.read_csv('weather.csv')\n",
    "        dt.drop(dt.columns[0], axis=1, inplace=True)\n",
    "        transform_boolean(dt)\n",
    "        ID_dataset=2\n",
    "        \n",
    "    elif choice == '3': \n",
    "        dt=pd.read_csv('iris.csv')\n",
    "        dt.drop(dt.columns[0], axis=1, inplace=True)\n",
    "        ID_dataset=3\n",
    "        \n",
    "    elif choice == '4':\n",
    "        dt=pd.read_csv('connect4.csv')\n",
    "        ID_dataset=4\n",
    "    \n",
    "    transform_boolean(dt)\n",
    "    \n",
    "    return dt, ID_dataset\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a9d4be",
   "metadata": {},
   "source": [
    "## Divisão dos dados\n",
    "\n",
    "[Go back to the top](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45e24a0",
   "metadata": {},
   "source": [
    "Este código destina se à chamada do menu, onde é possível escolher se há ou não divisão de dados (em caso afirmativo podemos escolher o tamanho dos dados de teste) e qual dataset se pretende usar (dentro dos disponibilizados pelo professor)\n",
    "\n",
    "Como output recebemos a árvore do dataset correspondente e em caso de divisão de dados recebemos também a accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e4ca5dbce26c55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T11:44:56.851028Z",
     "start_time": "2024-05-20T11:44:17.834289Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dt,div,tamanho,ID_dataset= menu_1()\n",
    "\n",
    "#dt=pd.read_csv('nomedoficheiro.csv')         #Aqui é possível acrescentar um novo dataset para ser gerada uma árvore a partir dele\n",
    "#dt.drop(dt1.columns[0], axis=1, inplace=True)   #Se tiver uma coluna com índices usar este comando\n",
    "\n",
    "class_imbalance =input(\"Quer aplicar uma solução para class imbalance? (y/n)\")\n",
    "\n",
    "if class_imbalance == 'y':\n",
    "    dt= over_sample(dt)\n",
    "\n",
    "if div:\n",
    "    train_set, test_set = train_test_split(dt, test_size=tamanho, random_state=42)\n",
    "    tree = learn_decision_tree(train_set,dt.columns[:-1], None)\n",
    "    print(\"Árvore de Decisão:\")\n",
    "    print_decision_tree(tree)\n",
    "\n",
    "    previsoes = prever_dataset(test_set, tree)\n",
    "    acc=accuracy(test_set, previsoes)\n",
    "    print()\n",
    "    print(\"Accuracy: \",acc)\n",
    "    \n",
    "else:\n",
    "    tree = learn_decision_tree(dt,dt.columns[:-1], None)\n",
    "    #print(tree)\n",
    "    print(\"Árvore de Decisão:\")\n",
    "    print_decision_tree(tree)\n",
    "    previsoes = prever_dataset(dt, tree)\n",
    "    acc=accuracy(dt, previsoes)\n",
    "    print()\n",
    "    print(\"Accuracy: \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54296d43",
   "metadata": {},
   "source": [
    "## Previsão de dados\n",
    "\n",
    "[Go back to the top](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fbed9d",
   "metadata": {},
   "source": [
    "### Apenas uma linha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6dce2f",
   "metadata": {},
   "source": [
    "Esta secção dedica-se à previsão de apenas um exemplo (inserido pelo utilizador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45223646156e999",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T11:44:59.901531Z",
     "start_time": "2024-05-20T11:44:56.853024Z"
    }
   },
   "outputs": [],
   "source": [
    "resp= input(\"Insira o novo exemplo: \")\n",
    "\n",
    "dt = predict_new_example(dt, resp)\n",
    "\n",
    "previsao = prever_dataset(dt, tree)\n",
    "previsao_final = previsao[len(previsao) - 1]\n",
    "\n",
    "\n",
    "print(\"Previsão: \", previsao_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7233666",
   "metadata": {},
   "source": [
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff757cd2",
   "metadata": {},
   "source": [
    "Nesta secção é possível inserir um ficheiro para ser avaliado. Para isso basta mudar 'nomedoficheiro' para o caminho onde se encontra o ficheiro e executar o código. Após a execução teremos a accuracy bem como as previsões de cada entrada do dataset."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab09623f",
   "metadata": {},
   "source": [
    "dt=pd.read_csv('teste.csv')   #Inserir aqui o nome do ficheiro a ser avaliado\n",
    "\n",
    "transform_boolean(dt)         #Transforma booleanos em 'Yes' and 'No'\n",
    "\n",
    "previsao = prever_dataset(dt, tree)\n",
    "\n",
    "#acc=accuracy(dt, previsoes)\n",
    "\n",
    "#print()\n",
    "#print(\"Accuracy: \",acc)\n",
    "for i in range (len(previsao)):\n",
    "    print(f\"Previsão {i}: \",previsao[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bff306",
   "metadata": {},
   "source": [
    "### Connect Four"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cad176",
   "metadata": {},
   "source": [
    "#### Funções relacionadas ao dataset 4\n",
    "\n",
    "-Função __transform_connect_four__(state): Esta função está responsável por receber um estado em forma de matriz e transformá-lo numa linha com as características do dataset 'connectfour'. É essencial para podermos prever o resultado de um estado.\n",
    "\n",
    "-Função __predict_move_tree__(dt,state): Esta função através do dataset recebido e do estado atual do jogo, está responsável por prever o melhor movimento e executá-lo. Gera os sucessores e faz a previsão final de cada um. Se for \"win\", o movimento é armazenado num vetor, onde no fim se este não estiver vazio, será feito um random desses movimentos. Caso seja vazio, significa que não houve nenhum resultado \"win\" e então é feito um movimento aleatório."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf23f9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T11:44:59.906857Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_connect_four_to_dataset(state):\n",
    "    resp=\"\"\n",
    "    linha=0\n",
    "    coluna=0\n",
    "    for i in range (42):\n",
    "        if linha == 6:\n",
    "            linha = 0\n",
    "            coluna += 1\n",
    "        if state[5-linha][coluna] == '-':\n",
    "            state[5-linha][coluna] = 'b'\n",
    "        elif state[5-linha][coluna] == 'X':\n",
    "            state[5-linha][coluna] = 'x'\n",
    "        elif state[5-linha][coluna] == 'O':\n",
    "            state[5-linha][coluna] = 'o'\n",
    "\n",
    "        resp = resp + state[5-linha][coluna] + \",\"\n",
    "        linha+=1\n",
    "        \n",
    "    resp = resp.rstrip(',')\n",
    "    return resp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9f879bcd9c67c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T11:44:59.904612Z",
     "start_time": "2024-05-20T11:44:59.904612Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_move_tree(dt,state):\n",
    "    \n",
    "    #print(\"Estado: \",state)\n",
    "    \n",
    "    sucessores, cols = state.successors()\n",
    "\n",
    "    movimentos=[]\n",
    "\n",
    "    for i in range(len(sucessores)):\n",
    "        \n",
    "        if sucessores[i] is None:\n",
    "            continue\n",
    "                \n",
    "        resp=transform_connect_four_to_dataset(sucessores[i].board)\n",
    "        \n",
    "        dt = predict_new_example(dt, resp)\n",
    "        previsao = prever_dataset(dt, tree)\n",
    "        previsao_final = previsao[len(previsao) - 1]\n",
    "        if previsao_final == \"win\":\n",
    "            movimentos.append(cols[i])\n",
    "\n",
    "    if movimentos == []:\n",
    "        possible_moves = [col for col in range(7) if not state.is_full(col)]\n",
    "        if possible_moves:\n",
    "            random_move = random.choice(possible_moves)  # Escolhe um movimento possível aleatório\n",
    "            state.move(random_move, state.turn)\n",
    "    else:\n",
    "        state.move(random.choice(movimentos), state.turn)\n",
    "        \n",
    "        \n",
    "\n",
    "game=ConnectFour()\n",
    "\n",
    "game.board = [[\"-\"] * 7 for _ in range(6)]\n",
    "\n",
    "\n",
    "while not (game.winner or game.is_board_full()):\n",
    "    if game.turn==\"X\":\n",
    "        predict_move_tree(dt,game)\n",
    "    else:\n",
    "        alpha = float('-inf')\n",
    "        beta = float('inf')\n",
    "                    \n",
    "        _,prox_move=game.alphabeta(5,alpha,beta,1)\n",
    "        game.move(prox_move,game.turn)\n",
    "    \n",
    "        game.check_winner()\n",
    "        print (game)\n",
    "\n",
    "\n",
    "if game.winner:\n",
    "    print(\"Game Over! Player\", game.player_winner, \"wins!!\")\n",
    "else:\n",
    "    print(\"Game Over! It's a draw\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd9daf2",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "[Go back to the top](#Índice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91b2c7a",
   "metadata": {},
   "source": [
    "#### Restaurant\n",
    "\n",
    "Este conjunto de dados contém informações sobre clientes e restaurantes, incluindo tipo de comida, tempo de espera, preço, etc. A variável de classe indica se o cliente irá ou não esperar para comer no restaurante.\n",
    "\n",
    "Este dataset serviu como dataset inicial para o desenvolvimento deste projeto, não apresentando grandes dificuldades.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a93d127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Alt</th>\n",
       "      <th>Bar</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Hun</th>\n",
       "      <th>Pat</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Res</th>\n",
       "      <th>Type</th>\n",
       "      <th>Est</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Some</td>\n",
       "      <td>$$$</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>French</td>\n",
       "      <td>0-10</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Full</td>\n",
       "      <td>$</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Thai</td>\n",
       "      <td>30-60</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X3</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Some</td>\n",
       "      <td>$</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Burger</td>\n",
       "      <td>0-10</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Full</td>\n",
       "      <td>$</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Thai</td>\n",
       "      <td>10-30</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Full</td>\n",
       "      <td>$$$</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>French</td>\n",
       "      <td>&gt;60</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Alt  Bar  Fri  Hun   Pat Price Rain  Res    Type    Est Class\n",
       "0  X1  Yes   No   No  Yes  Some   $$$   No  Yes  French   0-10   Yes\n",
       "1  X2  Yes   No   No  Yes  Full     $   No   No    Thai  30-60    No\n",
       "2  X3   No  Yes   No   No  Some     $   No   No  Burger   0-10   Yes\n",
       "3  X4  Yes   No  Yes  Yes  Full     $   No   No    Thai  10-30   Yes\n",
       "4  X5  Yes   No  Yes   No  Full   $$$   No  Yes  French    >60    No"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=pd.read_csv('restaurant.csv')\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96d6d18c",
   "metadata": {},
   "source": [
    "<Pat>\n",
    "  Some: Yes (4)\n",
    "  Full:\n",
    "  <Hun>\n",
    "      Yes:\n",
    "    <Type>\n",
    "          French: No (0)\n",
    "          Thai:\n",
    "      <Fri>\n",
    "              No: No (1)\n",
    "              Yes: Yes (1)\n",
    "          Italian: No (1)\n",
    "          Burger: Yes (1)\n",
    "      No: No (2)\n",
    "  None: No (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08f08d4",
   "metadata": {},
   "source": [
    "#### Weather\n",
    "\n",
    "Este conjunto de dados contém informações sobre condições climáticas para jogar tênis. O objetivo é ensinar uma árvore de decisão para que possa decidir quais são as melhores condições para jogar tênis.\n",
    "\n",
    "Este dataset já apresenta dados numéricos bem como dados booleanos, os quais tivemos de fazer alterações para que o nosso algoritmo funcionasse. Vimos também que apresentava um problema de class imbalance, ou seja, uma das classes (neste caso a class 'Yes') é superior à outra (neste caso a class 'No')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fca0839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Windy</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sunny</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>overcast</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>rainy</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>rainy</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   Weather  Temp  Humidity  Windy Play\n",
       "0   1     sunny    85        85  False   no\n",
       "1   2     sunny    80        90   True   no\n",
       "2   3  overcast    83        86  False  yes\n",
       "3   4     rainy    70        96  False  yes\n",
       "4   5     rainy    68        80  False  yes"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=pd.read_csv('weather.csv')\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18c4fec7",
   "metadata": {},
   "source": [
    "<Temp>\n",
    "  <= 83:\n",
    "    <Humidity>\n",
    "      <= 86:\n",
    "        <Weather>\n",
    "          overcast: yes (3)\n",
    "          rainy:\n",
    "            <Windy>\n",
    "              No: yes (2)\n",
    "              Yes: no (1)\n",
    "          sunny: yes (2)\n",
    "      > 86:\n",
    "        <Weather>\n",
    "          sunny: no (2)\n",
    "          rainy:\n",
    "            <Windy>\n",
    "              No: yes (1)\n",
    "              Yes: no (1)\n",
    "          overcast: yes (1)\n",
    "  > 83: no (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2472cab0",
   "metadata": {},
   "source": [
    "#### Iris\n",
    "\n",
    "Este conjunto de dados contém informações numéricas sobre plantas de três classes: iris setosa, iris virginica e iris versicolor. Os atributos são comprimento e largura da pétala e comprimento e largura da sépala. O objetivo é ensinar uma árvore de decisão para que possa determinar qual classe uma planta pertence, dadas as suas medidas de sépala e pétala. \n",
    "\n",
    "Este dataset apresenta apenas dados numéricos e uma classe com três valores diferentes. Em relação aos restantes este dataset também apresenta mais entradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "763a9de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sepallength</th>\n",
       "      <th>sepalwidth</th>\n",
       "      <th>petallength</th>\n",
       "      <th>petalwidth</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  sepallength  sepalwidth  petallength  petalwidth        class\n",
       "0   1          5.1         3.5          1.4         0.2  Iris-setosa\n",
       "1   2          4.9         3.0          1.4         0.2  Iris-setosa\n",
       "2   3          4.7         3.2          1.3         0.2  Iris-setosa\n",
       "3   4          4.6         3.1          1.5         0.2  Iris-setosa\n",
       "4   5          5.0         3.6          1.4         0.2  Iris-setosa"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=pd.read_csv('iris.csv')\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f454efc6",
   "metadata": {},
   "source": [
    "<petallength>\n",
    "  <= 1.9: Iris-setosa (50)\n",
    "  > 1.9:\n",
    "    <petalwidth>\n",
    "      <= 1.7:\n",
    "        <sepallength>\n",
    "          <= 7.0:\n",
    "            <sepalwidth>\n",
    "              <= 2.8: Iris-versicolor (31)\n",
    "              > 2.8: Iris-versicolor (22)\n",
    "          > 7.0: Iris-virginica (1)\n",
    "      > 1.7:\n",
    "        <sepallength>\n",
    "          <= 5.9:\n",
    "            <sepalwidth>\n",
    "              <= 3.0: Iris-virginica (6)\n",
    "              > 3.0: Iris-versicolor (1)\n",
    "          > 5.9: Iris-virginica (39)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e29b50",
   "metadata": {},
   "source": [
    "#### Connect Four\n",
    "\n",
    "Este é um conjunto de dados onde cada linha corresponde a uma configuração de tabuleiro do jogo connect four. O objetivo é induzir uma árvore de decisão para este conjunto de dados e através da mesma prever onde jogar na próxima jogada.\n",
    "\n",
    "Este dataset apresenta muitas entradas (cerca de 67000)\n",
    "\n",
    "Usando este dataset, iremos recorrer às funções do primeiro trabalho para colocar o AlphaBeta a jogar contra o DecisionTree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65177a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a4</th>\n",
       "      <th>a5</th>\n",
       "      <th>a6</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>...</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>g5</th>\n",
       "      <th>g6</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  a1 a2 a3 a4 a5 a6 b1 b2 b3 b4  ... f4 f5 f6 g1 g2 g3 g4 g5 g6  class\n",
       "0  b  b  b  b  b  b  b  b  b  b  ...  b  b  b  b  b  b  b  b  b    win\n",
       "1  b  b  b  b  b  b  b  b  b  b  ...  b  b  b  b  b  b  b  b  b    win\n",
       "2  b  b  b  b  b  b  o  b  b  b  ...  b  b  b  b  b  b  b  b  b    win\n",
       "3  b  b  b  b  b  b  b  b  b  b  ...  b  b  b  b  b  b  b  b  b    win\n",
       "4  o  b  b  b  b  b  b  b  b  b  ...  b  b  b  b  b  b  b  b  b    win\n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=pd.read_csv('connect4.csv')\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1947b474",
   "metadata": {},
   "source": [
    "## Testes e Resultados\n",
    "\n",
    "[Go back to the top](#Índice)\n",
    "\n",
    "Nesta seccção estarão presentes testes onde foram alterados alguns parâmetros e iremos analisar e discutir os resultados obtidos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee36ca4",
   "metadata": {},
   "source": [
    "### Comparação de árvores com e sem divisão dos dados\n",
    "\n",
    "Neste ponto iremos comparar as árvores geradas sem divisão de dados e as árvores geradas com 0.7 de tamanho de dados de treino para os primeiros três datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f739e126",
   "metadata": {},
   "source": [
    "##### S/ divisão"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ade7774",
   "metadata": {},
   "source": [
    "<Pat>\n",
    "  Some: Yes (4)\n",
    "  Full:\n",
    "  <Hun>\n",
    "      Yes:\n",
    "    <Type>\n",
    "          French: No (0)\n",
    "          Thai:\n",
    "      <Fri>\n",
    "              No: No (1)\n",
    "              Yes: Yes (1)\n",
    "          Italian: No (1)\n",
    "          Burger: Yes (1)\n",
    "      No: No (2)\n",
    "  None: No (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1def5949",
   "metadata": {},
   "source": [
    "##### C/ divisão"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a569cdd9",
   "metadata": {},
   "source": [
    "<Pat>\n",
    "  Some: Yes (3)\n",
    "  Full:\n",
    "    <Type>\n",
    "      Italian: No (0)\n",
    "      Thai:\n",
    "        <Fri>\n",
    "          No: No (1)\n",
    "          Yes: Yes (1)\n",
    "      Burger: Yes (1)\n",
    "      French: No (1)\n",
    "  None: No (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00566e3a",
   "metadata": {},
   "source": [
    "A accuracy depois de dividir os dados em treino e teste foi de 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8320016",
   "metadata": {},
   "source": [
    "##### S/ divisão"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20f9bd19",
   "metadata": {},
   "source": [
    "<Temp>\n",
    "  <= 83:\n",
    "    <Humidity>\n",
    "      <= 86:\n",
    "        <Weather>\n",
    "          overcast: yes (3)\n",
    "          rainy:\n",
    "            <Windy>\n",
    "              No: yes (2)\n",
    "              Yes: no (1)\n",
    "          sunny: yes (2)\n",
    "      > 86:\n",
    "        <Weather>\n",
    "          sunny: no (2)\n",
    "          rainy:\n",
    "            <Windy>\n",
    "              No: yes (1)\n",
    "              Yes: no (1)\n",
    "          overcast: yes (1)\n",
    "  > 83: no (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a3df53",
   "metadata": {},
   "source": [
    "##### C/ divisão"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fdf2ccc0",
   "metadata": {},
   "source": [
    "<Temp>\n",
    "  <= 70: yes (4)\n",
    "  > 70:\n",
    "    <Humidity>\n",
    "      <= 86: yes (2)\n",
    "      > 86: no (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b82f20e",
   "metadata": {},
   "source": [
    "A accuracy depois de dividir os dados em treino e teste foi de 40%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f2608",
   "metadata": {},
   "source": [
    "Através dos resultados obtidos, podemos verificar diferenças nas árvores geradas dos dois primeiros datasets, sendo o segundo mais evidente. Como há menos dados a serem usados para construir a árvore de decisão, isso significa menos informação o que pode levar a decisões \"precipitadas\" da árvore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba65746a",
   "metadata": {},
   "source": [
    "##### S/ divisão"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0472cb3",
   "metadata": {},
   "source": [
    "<petallength>\n",
    "  <= 1.9: Iris-setosa (50)\n",
    "  > 1.9:\n",
    "    <petalwidth>\n",
    "      <= 1.7:\n",
    "        <sepallength>\n",
    "          <= 7.0:\n",
    "            <sepalwidth>\n",
    "              <= 2.8: Iris-versicolor (31)\n",
    "              > 2.8: Iris-versicolor (22)\n",
    "          > 7.0: Iris-virginica (1)\n",
    "      > 1.7:\n",
    "        <sepallength>\n",
    "          <= 5.9:\n",
    "            <sepalwidth>\n",
    "              <= 3.0: Iris-virginica (6)\n",
    "              > 3.0: Iris-versicolor (1)\n",
    "          > 5.9: Iris-virginica (39)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211796a2",
   "metadata": {},
   "source": [
    "##### C/ divisão"
   ]
  },
  {
   "cell_type": "raw",
   "id": "226ce231",
   "metadata": {},
   "source": [
    "<petallength>\n",
    "  <= 1.9: Iris-setosa (31)\n",
    "  > 1.9:\n",
    "    <petalwidth>\n",
    "      <= 1.7:\n",
    "        <sepallength>\n",
    "          <= 7.0:\n",
    "            <sepalwidth>\n",
    "              <= 2.8: Iris-versicolor (25)\n",
    "              > 2.8: Iris-versicolor (15)\n",
    "          > 7.0: Iris-virginica (1)\n",
    "      > 1.7:\n",
    "        <sepallength>\n",
    "          <= 5.9:\n",
    "            <sepalwidth>\n",
    "              <= 3.0: Iris-virginica (5)\n",
    "              > 3.0: Iris-versicolor (1)\n",
    "          > 5.9: Iris-virginica (27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a0c83a",
   "metadata": {},
   "source": [
    "Neste caso a accuracy subiu de 97% para 100%. Isto pode dever-se ao facto de quando usamos a divisão dos dados, haver menos para avaliar e por essa razão a accuracy subir para 100%. Outra razão poderá ser a redução de overfitting já que são usados menos dados para construir a árvore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4665a0",
   "metadata": {},
   "source": [
    "### Comparação entre os diferentes tamanhos de teste e treino\n",
    "\n",
    "Neste ponto irá ser estudada a influência dos diferentes tamanhos de teste e treino na construção da árvore de treino."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dcf371",
   "metadata": {},
   "source": [
    "#### Restaurant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eacc977",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.2 // 67%"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd7ff654",
   "metadata": {},
   "source": [
    "<Pat>\n",
    "  Full:\n",
    "    <Est>\n",
    "      0-10: No (0)\n",
    "      >60: No (2)\n",
    "      30-60:\n",
    "        <Bar>\n",
    "          No: No (1)\n",
    "          Yes: Yes (1)\n",
    "      10-30: Yes (1)\n",
    "  Some: Yes (3)\n",
    "  None: No (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc64f60c",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.4 // 80%"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ecf48e66",
   "metadata": {},
   "source": [
    "<Pat>\n",
    "  Some: Yes (2)\n",
    "  Full:\n",
    "    <Type>\n",
    "      Italian: No (0)\n",
    "      Thai:\n",
    "        <Fri>\n",
    "          No: No (1)\n",
    "          Yes: Yes (1)\n",
    "      Burger: Yes (1)\n",
    "      French: No (1)\n",
    "  None: No (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb7e30b",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.6 // 63%"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80ac64b2",
   "metadata": {},
   "source": [
    "<Hun>\n",
    "  No: No (2)\n",
    "  Yes: Yes (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d2161",
   "metadata": {},
   "source": [
    "Nestes exemplos conseguimos ver um aumento e uma descida na accuracy. Quando o tamanho de teste é \"pequeno\" provavelmente ocorre overfitting já que a accuracy desceu em relação ao tamanho de teste 0.4. Quando o tamanho de teste é demasiado grande, não há dados suficientes para treinar a árvore e nesse caso a accuracy também é bastante baixa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215890c5",
   "metadata": {},
   "source": [
    "#### Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f0208c",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.2 // 33%"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e78d3af",
   "metadata": {},
   "source": [
    "<Temp>\n",
    "  <= 80:\n",
    "    <Humidity>\n",
    "      <= 80:\n",
    "        <Weather>\n",
    "          rainy:\n",
    "            <Windy>\n",
    "              Yes: no (1)\n",
    "              No: yes (1)\n",
    "          sunny: yes (2)\n",
    "          overcast: yes (1)\n",
    "      > 80:\n",
    "        <Weather>\n",
    "          overcast: no (0)\n",
    "          sunny: no (2)\n",
    "          rainy:\n",
    "            <Windy>\n",
    "              Yes: no (1)\n",
    "              No: yes (1)\n",
    "  > 80: yes (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cd4105",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.4 // 50%"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72080fc8",
   "metadata": {},
   "source": [
    "<Temp>\n",
    "  <= 70: yes (3)\n",
    "  > 70:\n",
    "    <Humidity>\n",
    "      <= 86: yes (2)\n",
    "      > 86: no (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a389855",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.6 // 44%"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a777756",
   "metadata": {},
   "source": [
    "<Temp>\n",
    "  <= 70: yes (3)\n",
    "  > 70:\n",
    "    <Humidity>\n",
    "      <= 70: yes (1)\n",
    "      > 70: no (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0295cd8",
   "metadata": {},
   "source": [
    "Como no exemplo anterior, as accuracys subiram e desceram devido às mesmas razões. Podemos ver que quando o tamanho de testes é baixo (e consequentemente o de treino é alto) a árvore é mais complexa o que leva a overfitting. Já quando é baixo, a árvore é demasiado simples o que leva também a uma accuracy baixa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a997438c",
   "metadata": {},
   "source": [
    "#### Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7d30b7",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.2 // 100%"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5abcde18",
   "metadata": {},
   "source": [
    "<petallength>\n",
    "  <= 1.9: Iris-setosa (40)\n",
    "  > 1.9:\n",
    "    <petalwidth>\n",
    "      <= 1.7:\n",
    "        <sepallength>\n",
    "          <= 7.0:\n",
    "            <sepalwidth>\n",
    "              <= 2.8: Iris-versicolor (25)\n",
    "              > 2.8: Iris-versicolor (19)\n",
    "          > 7.0: Iris-virginica (1)\n",
    "      > 1.7:\n",
    "        <sepallength>\n",
    "          <= 5.9:\n",
    "            <sepalwidth>\n",
    "              <= 3.0: Iris-virginica (6)\n",
    "              > 3.0: Iris-versicolor (1)\n",
    "          > 5.9: Iris-virginica (28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8964bc37",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.4 // 98%"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18eeb142",
   "metadata": {},
   "source": [
    "<petallength>\n",
    "  <= 1.9: Iris-setosa (27)\n",
    "  > 1.9:\n",
    "    <petalwidth>\n",
    "      <= 1.7:\n",
    "        <sepallength>\n",
    "          <= 7.0:\n",
    "            <sepalwidth>\n",
    "              <= 2.6: Iris-versicolor (15)\n",
    "              > 2.6: Iris-versicolor (18)\n",
    "          > 7.0: Iris-virginica (1)\n",
    "      > 1.7:\n",
    "        <sepallength>\n",
    "          <= 5.9:\n",
    "            <sepalwidth>\n",
    "              <= 3.0: Iris-virginica (5)\n",
    "              > 3.0: Iris-versicolor (1)\n",
    "          > 5.9: Iris-virginica (23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f74066",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.6 // 91%"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0dc8b1d9",
   "metadata": {},
   "source": [
    "<petallength>\n",
    "  <= 1.7: Iris-setosa (15)\n",
    "  > 1.7:\n",
    "    <petalwidth>\n",
    "      <= 1.6:\n",
    "        <sepallength>\n",
    "          <= 7.0:\n",
    "            <sepalwidth>\n",
    "              <= 2.2: Iris-virginica (1)\n",
    "              > 2.2: Iris-versicolor (22)\n",
    "          > 7.0: Iris-virginica (1)\n",
    "      > 1.6: Iris-virginica (21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4900a72",
   "metadata": {},
   "source": [
    "Neste caso, ao contrário dos anteriores, à medida que o tamanho de teste aumenta a accuracy diminui. Isso deve-se ao facto de, como o dataset é mais complexo e maior, os dados de treino irão ser mais e por essa razão a árvore ficará mais robusta e por consequência aumenta a accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5fe5c1",
   "metadata": {},
   "source": [
    "#### Connect Four"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183436c6",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.2 // 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61c0e3",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.4 // 73%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbab1ab",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.6 // 72%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34519b4",
   "metadata": {},
   "source": [
    "Por último, fizemos com o quarto dataset onde obtivemos accuracys semelhantes em todos os testes, o que é esperado devido à dimensão do dataset e à semelhança entre os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c9ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "datasets = ['Restaurante', 'Weather', 'Iris', 'Connect4']\n",
    "divisions = ['0.2', '0.4', '0.6']\n",
    "values1 = [67, 80, 63, 33, 50, 44, 100, 98, 91, 75, 73, 72]\n",
    "\n",
    "x = np.arange(len(datasets))\n",
    "width = 0.2 \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "bars1 = ax.bar(x - width, values1[0::3], width, label='0.2', color='turquoise')\n",
    "bars2 = ax.bar(x, values1[1::3], width, label='0.4', color='indigo')\n",
    "bars3 = ax.bar(x + width, values1[2::3], width, label='0.6', color='orange')\n",
    "\n",
    "ax.set_xlabel('Datasets')\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title('Diferentes tamanhos de divisões')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(datasets)\n",
    "ax.legend()\n",
    "\n",
    "plt.ylim(0, 100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c7a562",
   "metadata": {},
   "source": [
    "### Over-Sampling\n",
    "\n",
    "Neste teste decidimos ajustar melhor os dados do dataset 'Weather' que apresentava dados com a classe desbalanceada, isto é, possuia mais dados com classe 'Yes' do que dados com classe 'No'.\n",
    "Vamos verificar se teve algum efeito na accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6442556f",
   "metadata": {},
   "source": [
    "#### Restaurant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6527d276",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.2 // 30%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c12bd6",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.4 // 60%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f3fe8f",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.6 // 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11346077",
   "metadata": {},
   "source": [
    "Como podemos observar, houve uma diminuição bastante acentuada nas accuracys em todos os testes, logo concluimos que este dataset não sofre do problema de class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd2d7f",
   "metadata": {},
   "source": [
    "#### Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10792def",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.2 // 25%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ef3b9e",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.4 // 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3b172",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.6 // 36%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcf0aa6",
   "metadata": {},
   "source": [
    "Através dos resultados obtidos, vemos que houve um aumento da accuracy. Com isto podemos afirmar que este dataset sofria bastante do problema de class imbalance, no entanto após a implementação da nossa solução, a accuracy subiu para um número considerável."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8211be",
   "metadata": {},
   "source": [
    "#### Iris\n",
    "\n",
    "Após a execução dos testes, os resultados não se alteraram. Esta solução implementada não se mostrou relevante para este dataset, concluindo assim que este dataset não sofre de class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f748c399",
   "metadata": {},
   "source": [
    "#### Connect Four"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d812f9",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.2 // 88%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb31193",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.4 // 84%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae5750b",
   "metadata": {},
   "source": [
    "##### Tamanho de teste = 0.6 // 79%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0009e8c",
   "metadata": {},
   "source": [
    "Os resultados mostram um aumento significativo na accuracy após a implementação desta solução para lidar com o class imbalance. Isso sugere que o dataset inicialmente sofria do problema de class imbalance, mas com a aplicação da nossa solução, a accuracy melhorou consideravelmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d81351",
   "metadata": {},
   "outputs": [],
   "source": [
    "values2 = [30, 60, 50, 25, 75, 36, 100, 98, 91, 88, 84, 79]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "bars1 = ax.bar(x - width, values2[0::3], width, label='0.2', color='turquoise')\n",
    "bars2 = ax.bar(x, values2[1::3], width, label='0.4', color='indigo')\n",
    "bars3 = ax.bar(x + width, values2[2::3], width, label='0.6', color='orange')\n",
    "\n",
    "ax.set_xlabel('Datasets')\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title('Diferentes tamanhos de divisões com over-sampling')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(datasets)\n",
    "ax.legend()\n",
    "\n",
    "plt.ylim(0, 100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725bf060",
   "metadata": {},
   "source": [
    "### Comparação entre AlphaBeta e DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5869cb36",
   "metadata": {},
   "source": [
    "Neste último teste, abordaremos o último dataset, onde este será responsável por decidir onde o jogador \"X\" irá colocar a sua peça. Para este teste decidimos usar o AlphaBeta como jogador \"O\" que foi implementado no trabalho anterior.\n",
    "\n",
    "É de esperar que o AlphaBeta ganhe as 10 partidas pois o DecisionTree não é adequado para este tipo de problemas."
   ]
  },
  {
   "cell_type": "raw",
   "id": "36a0c3cc",
   "metadata": {},
   "source": [
    "0 10 0 DecisionTree AlphaBeta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3d983e",
   "metadata": {},
   "source": [
    "Como podemos observar, os resultados foram de encontro aos esperados, já que o DecisionTree em caso de ter vários estados com classe \"win\" é escolhido aleatoriamente um movimento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732af8f9",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cce80cc",
   "metadata": {},
   "source": [
    "Com este trabalho conseguimos aprender um pouco mais sobre a implementação e o desenvolvimento de uma DecisionTree. Ao longo do nosso trabalho fomos encontrando alguns problemas nos datasets, os quais resolvemos adaptando o nosso algoritmo aos mesmos.\n",
    "\n",
    "Decidimos ainda fazer alguns testes para compararmos alguns parâmetros e vermos a influência de cada um na accuracy da árvore gerada. Observamos que a divisão do dataset em treino e teste alterou a accuracy. Mudando o tamanho do teste observamos também descidas e subidas na accuracy final.\n",
    "Em termos de pré processamento, para além das funções iniciais, implementamos também uma solução para o problema de class imbalance que se mostrou bastante eficaz na redução deste problema no dataset 2 e 4.\n",
    "\n",
    "Por fim, decidimos testar o DecisionTree contra o algoritmo AlphaBeta e este, como era de esperar, perdeu as 10 partidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d5ae1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
